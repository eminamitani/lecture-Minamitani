{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ゼロから始める簡単NNP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNPとは？？\n",
    "Neural Network Potentialの略です。原子構造の情報を受け取って、エネルギーの値を予測する、ニューラルネットワークベースの機械学習モデルです。第一原理計算での構造とエネルギーの関係を再現するように、第一原理計算結果を使って学習させる仕組みを使っています。\n",
    "\n",
    "この最も単純なケースを試してみましょう。今回扱うのは、結晶Siです。分子動力学法のトラジェクトリーを使って、様々な温度での熱ゆらぎが加わっていたり、密度が異なった状態での1250パターンの構造とエネルギーの情報を集めてあるので、それを学習データにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NNP stands for Neural Network Potential. It is a neural network-based machine learning model that receives information about atomic structure and predicts energy values. It uses a mechanism to train the model using ab initio results so that it replicates the relationship between structure and energy.\n",
    "\n",
    "Let us try this simplest case. We will be dealing with crystalline Si. Using molecular dynamics trajectories, we have collected information on the structure and energy of 1250 patterns at various temperatures with added thermal fluctuations and different densities, which we will use as training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 対称性関数の計算結果のロード\n",
    "構造とエネルギーの関係を学ばせるにあたって、まず構造をニューラルネットワーク的に扱いやすいデータに変換する必要があります。\n",
    "その方法の一つが対称性関数です。\n",
    "\n",
    "対称性関数の説明や計算は別のファイルにまとめているので、そちらを見てください。\n",
    "https://github.com/eminamitani/sample_NNP/blob/main/make_desc.ipynb\n",
    "\n",
    "今回は時間短縮のため保存しておいたデータを使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for students to learn the relationship between structure and energy, it is first necessary to convert the structure into data that is easy to handle in a neural network manner.\n",
    "One of the methods is the symmetry function.\n",
    "\n",
    "The explanation and calculation of the symmetry function are summarized in another file.\n",
    "https://github.com/eminamitani/sample_NNP/blob/main/make_desc.ipynb\n",
    "\n",
    "This time we will use the data we have saved to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "desc=np.load('desc.npy')\n",
    "label=np.load('label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 64, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データがどんな形か確認してみましょう。descは計算された対称性関数の11の値（最初の値は、G0と表記されるシンプルな動径分布に対応します）を保持していて、labelは系の原子あたりの平均エネルギーの情報を持っています。(全エネルギーそのままだと値が大きすぎるので)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the data looks like: desc holds the 11 values of the calculated symmetry function (the first value corresponds to a simple radial distribution, denoted G0), and label holds information on the average energy per atom of the system. (The values are too large if the total energy is kept as it is.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13.571609  ,  9.172703  ,  6.4423614 ,  3.4930756 ,  1.3537661 ,\n",
       "         0.35307807,  0.03834928,  0.7360559 ,  0.43611127,  0.28210217,\n",
       "         0.05149077], dtype=float32),\n",
       " -5.8122244)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc[0,0,:], label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14.427327  ,  9.910984  ,  7.078461  ,  3.9639223 ,  1.6263943 ,\n",
       "         0.4749474 ,  0.06694016,  1.0451641 ,  0.593504  ,  0.4443306 ,\n",
       "         0.08542389], dtype=float32),\n",
       " -5.812823)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc[1,0,:], label[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対称性関数の値にもそれなりにばらつきがありそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークの実装では配列の形を勘違いしてミスをすることが多いので確認しておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1250, 64, 11), (1250,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本当はデータを正規化したほうが良いのですが、ひとまず単純に処理してみましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ニューラルネットワークの定義\n",
    " 今回は、ニューラルネットワークというと真っ先にイメージされる多層パーセプトロンを使います。\n",
    "\n",
    " このモデルでは、11の対称性関数の値を受け取って、それをノード数20の隠れ層に渡し、最終的に一つの出力を得る形になっています。\n",
    " この出力は「原子ひとつあたりのエネルギー」に相当すると考えます。原子ひとつあたりのエネルギーが物理的にきちんと定義できるのかはさておき、それらを足し上げると、系の全エネルギーになるようにネットワーク中の重みやバイアスを最適化していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this case, we will use a multilayer perceptron, which is the first thing you think of when you think of neural networks.\n",
    "\n",
    " In this model, we take the values of 11 symmetry functions and pass them to a hidden layer with 20 nodes to obtain one final output.\n",
    " This output corresponds to \"energy per atom. We will optimize the weights and biases in the network so that the total energy of the system is obtained by adding up the energy per atom, regardless of whether the energy per atom can be properly defined physically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    #n_sf : number of symmetry function\n",
    "    #two-hidden layer\n",
    "    #output is energy per atom\n",
    "    def __init__(self,n_sf,n_hidden):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(n_sf, n_hidden)\n",
    "        self.a1  = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.a2  = nn.Tanh()\n",
    "        self.fc3 = nn.Linear(n_hidden,1)\n",
    "\n",
    "\n",
    "        #He initialization\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        self.results={}\n",
    "\n",
    "        self.layers=[self.fc1, self.a1, self.fc2, self.a2, self.fc3]\n",
    "\n",
    "    #tahn actination function\n",
    "    #two hidden layer\n",
    "    #evaluate eneergy & derivative in forward run\n",
    "    def forward(self,x):\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x=layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データとテストデータの分割\n",
    "機械学習では過学習（使ったデータにはよく合うが、それ以外のデータにはうまく対応できない）がつきものなので、汎化性能を調べるために、学習データとテストデータの分割を行います。今回は8割を学習データ、2割をテストデータにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since machine learning always involves over-learning (a good fit to the data used but not to other data), we will split the training data and test data in order to examine generalization performance. In this case, 80% of the data will be training data and 20% will be test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(desc, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorchはテンソルを入力として受け取り、出力もテンソルにすることができます。上記の`Net`クラスで実装されているモデルはベクトルを受け取ることを前提にかかれていますが、それが積み上がってテンソルになった入力に対しても柔軟に処理することができます。イメージ的に分かりにくいので、実際にやってみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch can take tensors as input and output tensors as output. The model implemented in the `Net` class above is written on the assumption that it receives vectors, but it can flexibly process inputs that have been accumulated into tensors. Since it is difficult to understand in terms of image, let's actually try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 64, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データ処理の概要確認\n",
    "#テンソルとしてデータを一気に流し込み、原子数の次元で和を取る\n",
    "nacsf=11\n",
    "model=Net(n_sf=nacsf,n_hidden=20)\n",
    "test_out=model(torch.tensor(X_train))\n",
    "test_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000データがあって、それぞれに（64,1）の配列が格納されている形式になっています。この64というのは原子数で、実際の正解データと比較するのは、64原子分の総和をとった値です。それは以下のようにして計算できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1000 data, each in the form of a (64,1) array stored. The 64 is the number of atoms, and the actual correct data to be compared is the summed value of the 64 atoms. It can be calculated as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_energy=torch.sum(test_out, dim=1)\n",
    "p_energy.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データローダーの定義\n",
    "効率よく学習させるためにはミニバッチ学習が欠かせません。機械学習では、モデルの出力と実際の値の差異のデータを使ってモデル内部のパラメータを更新していくのですが、各データで毎回更新を行っていると時間がかかりますし、学習もなかなか安定しません。なので、データをある程度の塊に分割して、その塊を処理するたびにパラメーター更新をするというような方法を取ります。これがミニバッチ学習です。このとき、毎回同じ塊を取ってくると、学習に偏りが生じてしまうので、塊の取り方も毎回ランダムにするほうが望ましいです。ただそれを実装するのは結構面倒です。pytorchやtensorflowではこういった動作をサポートするためのデータローダーの一式が備わっています。というわけで、そのためのデータローダーを組みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-batch learning is essential for efficient learning. In machine learning, the parameters inside the model are updated using data on the difference between the model output and actual values, but updating each piece of data each time takes time and learning is not stable. Therefore, we divide the data into a certain number of chunks and update the parameters each time the chunks are processed. This is mini-batch learning. In this case, if the same chunks of data are taken every time, the learning process will be biased, so it is preferable to randomize the way the chunks are taken every time. Pytorch and tensorflow have a set of data loaders to support this kind of behavior. So we will build a data loader for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchのtensor型に変換します。y_train, y_testはモデルの出力と整合させるために、unsqueeze(1)で余分な次元をつけています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts to torch tensor type. y_train, y_test are given an extra dimension by unsqueeze(1) to make them consistent with the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.tensor(X_train)\n",
    "X_test=torch.tensor(X_test)\n",
    "y_train=torch.tensor(y_train).unsqueeze(1)\n",
    "y_test=torch.tensor(y_test).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataset\n",
    "train_dset=[(data,label) for data, label in zip(X_train, y_train)]\n",
    "test_dset=[(data,label) for data, label in zip(X_test, y_test)]\n",
    "nbatch=100\n",
    "train_loader =torch.utils.data.DataLoader(train_dset, batch_size=nbatch, shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_dset, batch_size=nbatch, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この`train_loader`や`test_loader`はイテレータというものになっています。（要はforループで順番にアクセスできます。）シャッフル済みのデータが取り出せる便利な仕組みと思っておくと良いと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `train_loader` and `test_loader` are called iterators. (In short, they can be accessed in order in a for loop.) You can think of it as a convenient mechanism to retrieve shuffled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習部分のコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ログ取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import datetime\n",
    "dir=os.path.join(\"./logs\", datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "writer = SummaryWriter(log_dir=dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習＆テスト結果のループ部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, test_loader,scheduler):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_t=0.0\n",
    "        loss_v=0.0\n",
    "\n",
    "        #ミニバッチ学習のために順番にアクセスしています\n",
    "        for train, train_labels in train_loader:\n",
    "            tmp=model(train)\n",
    "            p_train=torch.sum(tmp, dim=1)/64.0\n",
    "\n",
    "            loss_train=loss_fn(p_train, train_labels)\n",
    "\n",
    "            #パラメータ更新には勾配(微分)をつかうのですが、ほっておくと結果が累積してしまうので、\n",
    "            #微分を計算する前に初期化します\n",
    "            optimizer.zero_grad()\n",
    "            #自動微分で勾配を計算します\n",
    "            loss_train.backward()\n",
    "\n",
    "            #パラメータを更新します\n",
    "            optimizer.step()\n",
    "            loss_t+=loss_train.item()\n",
    "        \n",
    "        #学習率を徐々に下げるスケジューラーというのを使っているので、\n",
    "        #エポックごとに更新していきます\n",
    "        scheduler.step()\n",
    "\n",
    "        #validation\n",
    "        with torch.no_grad():\n",
    "            for val, val_labels in test_loader:\n",
    "                p_val= torch.sum(model(val),dim=1)/64.0\n",
    "                loss_val=loss_fn(p_val, val_labels)\n",
    "                loss_v+=loss_val.item()\n",
    "        \n",
    "        writer.add_scalar(\"loss_train\", loss_t/len(train_loader), epoch)  \n",
    "        writer.add_scalar(\"loss_val\", loss_v/len(test_loader), epoch)  \n",
    "        \n",
    "        if epoch == 1 or epoch %100 ==0:\n",
    "            print('Epoch %d, Training Loss %f' %(epoch, loss_t/len(train_loader)))\n",
    "            print('\\t Validation Loss %f' %(loss_v/len(test_loader)))\n",
    "    \n",
    "    writer.close()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータの更新はAdamで行います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters(), lr=0.001)\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "scheduler = MultiStepLR(optimizer, milestones=[2000,3000],gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss 40.388465\n",
      "\t Validation Loss 36.554273\n",
      "Epoch 100, Training Loss 0.003750\n",
      "\t Validation Loss 0.003871\n",
      "Epoch 200, Training Loss 0.003696\n",
      "\t Validation Loss 0.003560\n",
      "Epoch 300, Training Loss 0.003681\n",
      "\t Validation Loss 0.003400\n",
      "Epoch 400, Training Loss 0.003671\n",
      "\t Validation Loss 0.003648\n",
      "Epoch 500, Training Loss 0.003655\n",
      "\t Validation Loss 0.003636\n",
      "Epoch 600, Training Loss 0.003623\n",
      "\t Validation Loss 0.003549\n",
      "Epoch 700, Training Loss 0.003575\n",
      "\t Validation Loss 0.003508\n",
      "Epoch 800, Training Loss 0.003522\n",
      "\t Validation Loss 0.003346\n",
      "Epoch 900, Training Loss 0.003440\n",
      "\t Validation Loss 0.003460\n",
      "Epoch 1000, Training Loss 0.003003\n",
      "\t Validation Loss 0.003150\n",
      "Epoch 1100, Training Loss 0.002197\n",
      "\t Validation Loss 0.002025\n",
      "Epoch 1200, Training Loss 0.001493\n",
      "\t Validation Loss 0.001098\n",
      "Epoch 1300, Training Loss 0.000843\n",
      "\t Validation Loss 0.000579\n",
      "Epoch 1400, Training Loss 0.000400\n",
      "\t Validation Loss 0.000391\n",
      "Epoch 1500, Training Loss 0.000361\n",
      "\t Validation Loss 0.000354\n",
      "Epoch 1600, Training Loss 0.000293\n",
      "\t Validation Loss 0.000270\n",
      "Epoch 1700, Training Loss 0.000309\n",
      "\t Validation Loss 0.000244\n",
      "Epoch 1800, Training Loss 0.000376\n",
      "\t Validation Loss 0.000557\n",
      "Epoch 1900, Training Loss 0.000348\n",
      "\t Validation Loss 0.000212\n",
      "Epoch 2000, Training Loss 0.000239\n",
      "\t Validation Loss 0.000255\n",
      "Epoch 2100, Training Loss 0.000215\n",
      "\t Validation Loss 0.000213\n",
      "Epoch 2200, Training Loss 0.000220\n",
      "\t Validation Loss 0.000218\n",
      "Epoch 2300, Training Loss 0.000225\n",
      "\t Validation Loss 0.000227\n",
      "Epoch 2400, Training Loss 0.000215\n",
      "\t Validation Loss 0.000241\n",
      "Epoch 2500, Training Loss 0.000300\n",
      "\t Validation Loss 0.000199\n",
      "Epoch 2600, Training Loss 0.000233\n",
      "\t Validation Loss 0.000202\n",
      "Epoch 2700, Training Loss 0.000265\n",
      "\t Validation Loss 0.000211\n",
      "Epoch 2800, Training Loss 0.000249\n",
      "\t Validation Loss 0.000261\n",
      "Epoch 2900, Training Loss 0.000219\n",
      "\t Validation Loss 0.000196\n",
      "Epoch 3000, Training Loss 0.000321\n",
      "\t Validation Loss 0.000195\n",
      "Epoch 3100, Training Loss 0.000222\n",
      "\t Validation Loss 0.000234\n",
      "Epoch 3200, Training Loss 0.000209\n",
      "\t Validation Loss 0.000205\n",
      "Epoch 3300, Training Loss 0.000322\n",
      "\t Validation Loss 0.000335\n",
      "Epoch 3400, Training Loss 0.000218\n",
      "\t Validation Loss 0.000211\n",
      "Epoch 3500, Training Loss 0.000261\n",
      "\t Validation Loss 0.000290\n",
      "Epoch 3600, Training Loss 0.000237\n",
      "\t Validation Loss 0.000200\n",
      "Epoch 3700, Training Loss 0.000224\n",
      "\t Validation Loss 0.000203\n",
      "Epoch 3800, Training Loss 0.000213\n",
      "\t Validation Loss 0.000269\n",
      "Epoch 3900, Training Loss 0.000212\n",
      "\t Validation Loss 0.000211\n",
      "Epoch 4000, Training Loss 0.000213\n",
      "\t Validation Loss 0.000199\n",
      "Epoch 4100, Training Loss 0.000222\n",
      "\t Validation Loss 0.000244\n",
      "Epoch 4200, Training Loss 0.000209\n",
      "\t Validation Loss 0.000190\n",
      "Epoch 4300, Training Loss 0.000220\n",
      "\t Validation Loss 0.000203\n",
      "Epoch 4400, Training Loss 0.000216\n",
      "\t Validation Loss 0.000222\n",
      "Epoch 4500, Training Loss 0.000199\n",
      "\t Validation Loss 0.000193\n",
      "Epoch 4600, Training Loss 0.000224\n",
      "\t Validation Loss 0.000205\n",
      "Epoch 4700, Training Loss 0.000212\n",
      "\t Validation Loss 0.000199\n",
      "Epoch 4800, Training Loss 0.000202\n",
      "\t Validation Loss 0.000187\n",
      "Epoch 4900, Training Loss 0.000199\n",
      "\t Validation Loss 0.000244\n",
      "Epoch 5000, Training Loss 0.000215\n",
      "\t Validation Loss 0.000186\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs=5000, optimizer=optimizer,model=model,\n",
    "             loss_fn=nn.MSELoss(), train_loader=train_loader, test_loader=test_loader,scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解と予測結果をプロットしてみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict=torch.sum(model(X_test),dim=1)/64.0\n",
    "    train=torch.sum(model(X_train),dim=1)/64.0\n",
    "    plt.gca().set_aspect('equal')\n",
    "    min=-6\n",
    "    max=-5.6\n",
    "    plt.xlim((min,max))\n",
    "    plt.ylim((min,max))\n",
    "    plt.plot([min,max],[min,max],color='gray')\n",
    "    \n",
    "    plt.scatter(y_train,train,c='red',s=2,alpha=0.5,label='train')\n",
    "    plt.scatter(y_test,predict,c='blue',s=2,alpha=0.5,label='test')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=0.013832 eV/atom\n"
     ]
    }
   ],
   "source": [
    "diff=(y_test-predict.to('cpu').detach().numpy()).numpy()\n",
    "RMSE=np.sqrt(np.mean(np.abs(diff)*np.abs(diff)))\n",
    "print('RMSE={0:f} eV/atom'.format(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そこまで外れてはいませんが、もうちょい精度が欲しいという感じですね。\n",
    "精度を上げるには、一つにはデータ数を増やすこと、もう一つは対称性関数のハイパーパラメータを調整したり数を増やすこと、あと、学習でのハイパーパラメータを調整することが挙げられます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not that far off, but I would like to see a little more accuracy.\n",
    "One way to increase accuracy is to increase the number of data, another is to adjust the hyperparameters of the symmetry function and increase the number of data, and another is to adjust the hyperparameters in the training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dev_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1224aa78933d76f3b87bf99e45c31cce45160fda9d38f1d681cad51c427d002b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
